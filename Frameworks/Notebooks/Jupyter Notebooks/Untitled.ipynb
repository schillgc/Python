{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching quote history for 'AAPL'\n",
      "Fetching quote history for 'AIG'\n",
      "Fetching quote history for 'AMZN'\n",
      "Fetching quote history for 'AXP'\n",
      "Fetching quote history for 'BA'\n",
      "Fetching quote history for 'BAC'\n",
      "Fetching quote history for 'CAJ'\n",
      "Fetching quote history for 'CAT'\n",
      "Fetching quote history for 'CL'\n",
      "Fetching quote history for 'CMCSA'\n",
      "Fetching quote history for 'COP'\n",
      "Fetching quote history for 'CSCO'\n",
      "Fetching quote history for 'CVC'\n",
      "Fetching quote history for 'CVS'\n",
      "Fetching quote history for 'CVX'\n",
      "Fetching quote history for 'DD'\n",
      "Fetching quote history for 'DELL'\n",
      "Fetching quote history for 'F'\n",
      "Fetching quote history for 'GD'\n",
      "Fetching quote history for 'GE'\n",
      "Fetching quote history for 'GS'\n",
      "Fetching quote history for 'GSK'\n",
      "Fetching quote history for 'HD'\n",
      "Fetching quote history for 'HMC'\n",
      "Fetching quote history for 'HPQ'\n",
      "Fetching quote history for 'IBM'\n",
      "Fetching quote history for 'JPM'\n",
      "Fetching quote history for 'K'\n",
      "Fetching quote history for 'KMB'\n",
      "Fetching quote history for 'KO'\n",
      "Fetching quote history for 'MAR'\n",
      "Fetching quote history for 'MCD'\n",
      "Fetching quote history for 'MMM'\n",
      "Fetching quote history for 'MSFT'\n",
      "Fetching quote history for 'NAV'\n",
      "Fetching quote history for 'NOC'\n",
      "Fetching quote history for 'NVS'\n",
      "Fetching quote history for 'PEP'\n",
      "Fetching quote history for 'PFE'\n",
      "Fetching quote history for 'PG'\n",
      "Fetching quote history for 'R'\n",
      "Fetching quote history for 'RTN'\n",
      "Fetching quote history for 'SAP'\n",
      "Fetching quote history for 'SNE'\n",
      "Fetching quote history for 'SNY'\n",
      "Fetching quote history for 'TM'\n",
      "Fetching quote history for 'TOT'\n",
      "Fetching quote history for 'TWX'\n",
      "Fetching quote history for 'TXN'\n",
      "Fetching quote history for 'UN'\n",
      "Fetching quote history for 'VLO'\n",
      "Fetching quote history for 'WFC'\n",
      "Fetching quote history for 'WMT'\n",
      "Fetching quote history for 'XOM'\n",
      "Fetching quote history for 'XRX'\n",
      "Fetching quote history for 'YHOO'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Apple, Amazon, Yahoo\n",
      "Cluster 2: Comcast, Cablevision, Time Warner\n",
      "Cluster 3: ConocoPhillips, Chevron, Total, Valero Energy, Exxon\n",
      "Cluster 4: Cisco, Dell, HP, IBM, Microsoft, SAP, Texas Instruments\n",
      "Cluster 5: Boeing, General Dynamics, Northrop Grumman, Raytheon\n",
      "Cluster 6: AIG, American express, Bank of America, Caterpillar, CVS, DuPont de Nemours, Ford, General Electrics, Goldman Sachs, Home Depot, JPMorgan Chase, Marriott, 3M, Ryder, Wells Fargo, Wal-Mart\n",
      "Cluster 7: McDonald's\n",
      "Cluster 8: GlaxoSmithKline, Novartis, Pfizer, Sanofi-Aventis, Unilever\n",
      "Cluster 9: Kellogg, Coca Cola, Pepsi\n",
      "Cluster 10: Colgate-Palmolive, Kimberly-Clark, Procter Gamble\n",
      "Cluster 11: Canon, Honda, Navistar, Sony, Toyota, Xerox\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# The data is from 2003 - 2008. This is reasonably calm: (not too long ago so\n",
    "# that we get high-tech firms, and before the 2008 crash). This kind of\n",
    "# historical data can be obtained for from APIs like the quandl.com and\n",
    "# alphavantage.co ones.\n",
    "\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'McDonald\\'s',\n",
    "    'PEP': 'Pepsi',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas Instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}\n",
    "\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for symbol in symbols:\n",
    "    print('Fetching quote history for %r' % symbol, file=sys.stderr)\n",
    "    url = ('https://raw.githubusercontent.com/scikit-learn/examples-data/'\n",
    "           'master/financial-data/{}.csv')\n",
    "    quotes.append(pd.read_csv(url.format(symbol)))\n",
    "\n",
    "close_prices = np.vstack([q['close'] for q in quotes])\n",
    "open_prices = np.vstack([q['open'] for q in quotes])\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close_prices - open_prices\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphicalLassoCV(cv=5)\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))\n",
    "\n",
    "# #############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=6)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.nipy_spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
